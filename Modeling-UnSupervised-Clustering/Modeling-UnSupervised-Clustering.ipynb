{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from hmmlearn import hmm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data:\n",
    "data = pd.read_csv('../Datasets/raw_datasets/data.csv', index_col='id')\n",
    "submission  = pd.read_csv('../Datasets/raw_datasets/sample_submission.csv')\n",
    "\n",
    "# Making a deep copy of the data\n",
    "data_copy = data.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer data\n",
    "int_data = data_copy.select_dtypes(int)\n",
    "\n",
    "# interger data column names as a list\n",
    "int_data_cols = int_data.columns.to_list()\n",
    "\n",
    "# float data\n",
    "float_data = data_copy.select_dtypes(float)\n",
    "\n",
    "# float data column names as a list\n",
    "float_data_cols = float_data.columns.to_list()\n",
    "\n",
    "# data_copy column names as a list\n",
    "data_copy_cols_list = data_copy.columns.to_list()\n",
    "\n",
    "# non-normal float data\n",
    "non_norm_float_data_list = data_copy_cols_list[22:29]\n",
    "\n",
    "# Selected Features\n",
    "selected_features_cols_list = int_data_cols + non_norm_float_data_list\n",
    "selected_data = data_copy[selected_features_cols_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler_power_transformer = Pipeline([\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    ('power_transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "# Apply transformation\n",
    "transformed_data = robust_scaler_power_transformer.fit_transform(selected_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Defining the number of clusters and the path to save output submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters to try\n",
    "n_clusters = 7\n",
    "\n",
    "# Output path\n",
    "output_path = '../Datasets/final/'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Initialize the results dictionary\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Defining Various Functions for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save results\n",
    "def save_results(labels, method, transformer_name):\n",
    "    output_df = pd.DataFrame({'Id': data.index, 'Predicted': labels})\n",
    "    filename = f\"{output_path}{method}_{n_clusters}_clusters_{transformer_name}.csv\"\n",
    "    output_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit GMM and evaluate\n",
    "def fit_gmm(data, transformer_name):\n",
    "    print(f\"Training GMM with {n_clusters} clusters using {transformer_name}...\")\n",
    "    start_time = time.time()\n",
    "    model = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    model.fit(data)\n",
    "    labels = model.predict(data)\n",
    "    silhouette = silhouette_score(data, labels)\n",
    "    davies_bouldin = davies_bouldin_score(data, labels)\n",
    "    end_time = time.time()\n",
    "    print(f\"GMM with {n_clusters} clusters using {transformer_name} completed in {end_time - start_time:.2f} seconds.\")\n",
    "    return silhouette, davies_bouldin, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fit BGMM and evaluate\n",
    "def fit_bgmm(data, transformer_name):\n",
    "    print(f\"Training BGMM with {n_clusters} clusters using {transformer_name}...\")\n",
    "    start_time = time.time()\n",
    "    model = BayesianGaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    model.fit(data)\n",
    "    labels = model.predict(data)\n",
    "    silhouette = silhouette_score(data, labels)\n",
    "    davies_bouldin = davies_bouldin_score(data, labels)\n",
    "    end_time = time.time()\n",
    "    print(f\"BGMM with {n_clusters} clusters using {transformer_name} completed in {end_time - start_time:.2f} seconds.\")\n",
    "    return silhouette, davies_bouldin, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training the clustering Algorithms and Saving the outputs for Submission csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GMM with 7 clusters using robust_scaler_power_transformer...\n",
      "GMM with 7 clusters using robust_scaler_power_transformer completed in 127.19 seconds.\n",
      "Training BGMM with 7 clusters using robust_scaler_power_transformer...\n",
      "BGMM with 7 clusters using robust_scaler_power_transformer completed in 137.25 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Fit GMM\n",
    "silhouette, davies_bouldin, labels = fit_gmm(transformed_data, \"robust_scaler_power_transformer\")\n",
    "results['GMM'] = {\n",
    "    'Silhouette Score': silhouette,\n",
    "    'Davies Bouldin Score': davies_bouldin,\n",
    "    'Labels': labels\n",
    "}\n",
    "save_results(labels, \"GMM\", \"robust_scaler_power_transformer\")\n",
    "\n",
    "# Fit BGMM\n",
    "silhouette, davies_bouldin, labels = fit_bgmm(transformed_data, \"robust_scaler_power_transformer\")\n",
    "results['BGMM'] = {\n",
    "    'Silhouette Score': silhouette,\n",
    "    'Davies Bouldin Score': davies_bouldin,\n",
    "    'Labels': labels\n",
    "}\n",
    "save_results(labels, \"BGMM\", \"robust_scaler_power_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GMM\n",
      "Silhouette Score: 0.03820238432848022\n",
      "Davies Bouldin Score: 3.5648224880234394\n",
      "------------------------------\n",
      "Model: BGMM\n",
      "Silhouette Score: 0.037749610172124484\n",
      "Davies Bouldin Score: 3.586824312339798\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for model in results:\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Silhouette Score: {results[model]['Silhouette Score']}\")\n",
    "    print(f\"Davies Bouldin Score: {results[model]['Davies Bouldin Score']}\")\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Checking the same process as done above for other number of clusters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the transformations\n",
    "# power_transformer = PowerTransformer()\n",
    "\n",
    "# robust_scaler_power_transformer = Pipeline([\n",
    "#     ('robust_scaler', RobustScaler()),\n",
    "#     ('power_transformer', PowerTransformer())\n",
    "# ])\n",
    "\n",
    "# # Define the number of clusters to try\n",
    "# n_clusters_list = [12, 6, 8, 7]\n",
    "\n",
    "# # Output path\n",
    "# output_path = '../Datasets/final/'\n",
    "\n",
    "# # Ensure the output directory exists\n",
    "# os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# # Initialize the results dictionary\n",
    "# results = {}\n",
    "\n",
    "# # Function to save results\n",
    "# def save_results(labels, method, n_clusters, transformer_name, index):\n",
    "#     output_df = pd.DataFrame({'Id': index, 'Predicted': labels})\n",
    "#     filename = f\"{output_path}{method}_{n_clusters}_clusters_{transformer_name}.csv\"\n",
    "#     output_df.to_csv(filename, index=False)\n",
    "\n",
    "# # Function to fit GMM and evaluate\n",
    "# def fit_gmm(data, n_clusters, transformer_name):\n",
    "#     print(f\"Training GMM with {n_clusters} clusters using {transformer_name}...\")\n",
    "#     start_time = time.time()\n",
    "#     model = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "#     model.fit(data)\n",
    "#     labels = model.predict(data)\n",
    "#     bic = model.bic(data)\n",
    "#     silhouette = silhouette_score(data, labels)\n",
    "#     davies_bouldin = davies_bouldin_score(data, labels)\n",
    "#     end_time = time.time()\n",
    "#     print(f\"GMM with {n_clusters} clusters using {transformer_name} completed in {end_time - start_time:.2f} seconds.\")\n",
    "#     return bic, silhouette, davies_bouldin, labels\n",
    "\n",
    "# # Function to fit BGMM and evaluate\n",
    "# def fit_bgmm(data, n_clusters, transformer_name):\n",
    "#     print(f\"Training BGMM with {n_clusters} clusters using {transformer_name}...\")\n",
    "#     start_time = time.time()\n",
    "#     model = BayesianGaussianMixture(n_components=n_clusters, random_state=42)\n",
    "#     model.fit(data)\n",
    "#     labels = model.predict(data)\n",
    "#     silhouette = silhouette_score(data, labels)\n",
    "#     davies_bouldin = davies_bouldin_score(data, labels)\n",
    "#     end_time = time.time()\n",
    "#     print(f\"BGMM with {n_clusters} clusters using {transformer_name} completed in {end_time - start_time:.2f} seconds.\")\n",
    "#     return None, silhouette, davies_bouldin, labels  # BIC not available for BGMM\n",
    "\n",
    "# # Function to fit DPGMM and evaluate\n",
    "# def fit_dpgmm(data, n_clusters, transformer_name):\n",
    "#     print(f\"Training DPGMM with {n_clusters} clusters using {transformer_name}...\")\n",
    "#     start_time = time.time()\n",
    "#     model = BayesianGaussianMixture(n_components=n_clusters, covariance_type='full', weight_concentration_prior_type='dirichlet_process', random_state=42)\n",
    "#     model.fit(data)\n",
    "#     labels = model.predict(data)\n",
    "#     silhouette = silhouette_score(data, labels)\n",
    "#     davies_bouldin = davies_bouldin_score(data, labels)\n",
    "#     end_time = time.time()\n",
    "#     print(f\"DPGMM with {n_clusters} clusters using {transformer_name} completed in {end_time - start_time:.2f} seconds.\")\n",
    "#     return None, silhouette, davies_bouldin, labels  # BIC not available for DPGMM\n",
    "\n",
    "# # Function to fit HMM and evaluate\n",
    "# def fit_hmm(data, n_clusters, transformer_name):\n",
    "#     print(f\"Training HMM with {n_clusters} clusters using {transformer_name}...\")\n",
    "#     start_time = time.time()\n",
    "#     model = hmm.GaussianHMM(n_components=n_clusters, covariance_type=\"full\", random_state=42)\n",
    "#     model.fit(data)\n",
    "#     labels = model.predict(data)\n",
    "#     silhouette = silhouette_score(data, labels)\n",
    "#     davies_bouldin = davies_bouldin_score(data, labels)\n",
    "#     end_time = time.time()\n",
    "#     print(f\"HMM with {n_clusters} clusters using {transformer_name} completed in {end_time - start_time:.2f} seconds.\")\n",
    "#     return None, silhouette, davies_bouldin, labels  # HMM does not provide BIC directly\n",
    "\n",
    "# # Apply transformations and fit models\n",
    "# for transformer, transformer_name in zip([power_transformer, robust_scaler_power_transformer], ['power_transformer', 'robust_scaler_power_transformer']):\n",
    "#     transformed_data = transformer.fit_transform(selected_data)\n",
    "#     results[transformer_name] = {}\n",
    "    \n",
    "#     for n_clusters in n_clusters_list:\n",
    "#         results[transformer_name][n_clusters] = {}\n",
    "\n",
    "#         # GMM\n",
    "#         bic, silhouette, davies_bouldin, labels = fit_gmm(transformed_data, n_clusters, transformer_name)\n",
    "#         results[transformer_name][n_clusters]['GMM'] = {\n",
    "#             'BIC': bic,\n",
    "#             'Silhouette Score': silhouette,\n",
    "#             'Davies Bouldin Score': davies_bouldin,\n",
    "#             'Labels': labels\n",
    "#         }\n",
    "#         save_results(labels, \"GMM\", n_clusters, transformer_name, data.index)\n",
    "\n",
    "#         # BGMM\n",
    "#         bic, silhouette, davies_bouldin, labels = fit_bgmm(transformed_data, n_clusters, transformer_name)\n",
    "#         results[transformer_name][n_clusters]['BGMM'] = {\n",
    "#             'BIC': bic,\n",
    "#             'Silhouette Score': silhouette,\n",
    "#             'Davies Bouldin Score': davies_bouldin,\n",
    "#             'Labels': labels\n",
    "#         }\n",
    "#         save_results(labels, \"BGMM\", n_clusters, transformer_name, data.index)\n",
    "\n",
    "#         # DPGMM\n",
    "#         bic, silhouette, davies_bouldin, labels = fit_dpgmm(transformed_data, n_clusters, transformer_name)\n",
    "#         results[transformer_name][n_clusters]['DPGMM'] = {\n",
    "#             'BIC': bic,\n",
    "#             'Silhouette Score': silhouette,\n",
    "#             'Davies Bouldin Score': davies_bouldin,\n",
    "#             'Labels': labels\n",
    "#         }\n",
    "#         save_results(labels, \"DPGMM\", n_clusters, transformer_name, data.index)\n",
    "\n",
    "#         # HMM\n",
    "#         _, silhouette, davies_bouldin, labels = fit_hmm(transformed_data, n_clusters, transformer_name)\n",
    "#         results[transformer_name][n_clusters]['HMM'] = {\n",
    "#             'BIC': None,  # Not available for HMM\n",
    "#             'Silhouette Score': silhouette,\n",
    "#             'Davies Bouldin Score': davies_bouldin,\n",
    "#             'Labels': labels\n",
    "#         }\n",
    "#         save_results(labels, \"HMM\", n_clusters, transformer_name, data.index)\n",
    "\n",
    "# # Print results\n",
    "# for transformer in results:\n",
    "#     print(f\"Results for {transformer}:\")\n",
    "#     for n_clusters in results[transformer]:\n",
    "#         print(f\"Number of clusters: {n_clusters}\")\n",
    "#         for model in results[transformer][n_clusters]:\n",
    "#             print(f\"Model: {model}\")\n",
    "#             print(f\"BIC: {results[transformer][n_clusters][model]['BIC']}\")\n",
    "#             print(f\"Silhouette Score: {results[transformer][n_clusters][model]['Silhouette Score']}\")\n",
    "#             print(f\"Davies Bouldin Score: {results[transformer][n_clusters][model]['Davies Bouldin Score']}\")\n",
    "#             print('-'*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
