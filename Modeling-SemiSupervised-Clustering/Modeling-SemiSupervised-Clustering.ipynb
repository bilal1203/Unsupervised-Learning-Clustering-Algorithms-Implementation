{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklego.mixture import BayesianGMMClassifier\n",
    "import pickle\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data:\n",
    "data = pd.read_csv('../Datasets/raw_datasets/data.csv', index_col='id')\n",
    "submission  = pd.read_csv('../Datasets/raw_datasets/sample_submission.csv')\n",
    "\n",
    "# Making a deep copy of the data\n",
    "data_copy = data.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer data\n",
    "int_data = data_copy.select_dtypes(int)\n",
    "\n",
    "# interger data column names as a list\n",
    "int_data_cols = int_data.columns.to_list()\n",
    "\n",
    "# float data\n",
    "float_data = data_copy.select_dtypes(float)\n",
    "\n",
    "# float data column names as a list\n",
    "float_data_cols = float_data.columns.to_list()\n",
    "\n",
    "# data_copy column names as a list\n",
    "data_copy_cols_list = data_copy.columns.to_list()\n",
    "\n",
    "# non-normal float data\n",
    "non_norm_float_data_list = data_copy_cols_list[22:29]\n",
    "\n",
    "# Selected Features\n",
    "selected_features_list = int_data_cols + non_norm_float_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler_power_transformer = Pipeline([\n",
    "    ('robust_scaler', RobustScaler()),\n",
    "    ('power_transformer', PowerTransformer())\n",
    "])\n",
    "\n",
    "transformed_selected_data = robust_scaler_power_transformer.fit_transform(data_copy)\n",
    "transformed_selected_data = pd.DataFrame(transformed_selected_data, columns=data_copy_cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters to try\n",
    "n_clusters = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To eveluate how good our cluster labels are.\n",
    "\n",
    "def score_clusters(X, predictions, silhouette = True, verbose=False):\n",
    "    \"\"\"Evaluate how good our cluster label predictions are\"\"\"\n",
    "    \n",
    "    db_score = davies_bouldin_score(X=X, labels=predictions)\n",
    "\n",
    "    ch_score = calinski_harabasz_score(X=X, labels=predictions)\n",
    "    \n",
    "    s_score = silhouette_score(X=X, labels=predictions, metric='euclidean')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"David Bouldin score: {0:0.4f}\".format(db_score))\n",
    "        print(\"Calinski Harabasz score: {0:0.3f}\".format(ch_score))\n",
    "        print(\"Silhouette score: {0:0.4f}\".format(s_score))\n",
    "        \n",
    "    return db_score, ch_score, s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(predict_number, best_cols = selected_features_list):\n",
    "    #initialise dataframe with 0's\n",
    "    predicted_probabilities = pd.DataFrame(np.zeros((len(data_copy),7)), columns=range(1,8))\n",
    "    # loop with a different random seeds\n",
    "    for i in range(predict_number):\n",
    "        print(\"=========\", i, \"==========\")\n",
    "        transformed_selected_data_sample = transformed_selected_data.sample(40000)\n",
    "        gmm = BayesianGaussianMixture(n_components=7, covariance_type = 'full', max_iter=300, init_params=\"kmeans\", n_init=3, random_state=i)\n",
    "        gmm.fit(transformed_selected_data_sample[selected_features_list])\n",
    "        pred_probs = gmm.predict_proba(transformed_selected_data[selected_features_list])\n",
    "        pred_probs = pd.DataFrame(pred_probs, columns=range(1,8))\n",
    "        \n",
    "        # ensuring clusters are labeled the same value at each fit\n",
    "        if i == 0:\n",
    "            initial_centers = gmm.means_\n",
    "        new_classes = []\n",
    "        for mean2 in gmm.means_:\n",
    "            #for the current center of the current gmm, find the distances to every center in the initial gmm\n",
    "            distances = [np.linalg.norm(mean1-mean2) for mean1 in initial_centers]\n",
    "            # select the class with the minimum distance\n",
    "            new_class = np.argmin(distances) + 1 #add 1 as our labels are 1-7 but index is 0-6\n",
    "            new_classes.append(new_class)\n",
    "        # if the mapping from old cluster labels to new cluster labels isn't 1 to 1\n",
    "        if len(new_classes) != len(set(new_classes)):\n",
    "            print(\"iteration\", i, \"could not determine the cluster label mapping, skipping\")\n",
    "            continue\n",
    "        #apply the mapping by renaming the dataframe columns representing the original labels to the new labels\n",
    "        pred_probs = pred_probs.rename(columns=dict(zip(range(1,8),new_classes)))\n",
    "        #add the current prediction probabilities to the overall prediction probabilities\n",
    "\n",
    "        predicted_probabilities = predicted_probabilities + pred_probs\n",
    "        # lets score the cluster labels each iteration to see if soft voting is helpful\n",
    "        score_clusters(transformed_selected_data[selected_features_list], predicted_probabilities.idxmax(axis=1), verbose=True)\n",
    "    \n",
    "    #normalise dataframe so each row sums to 1\n",
    "    predicted_probabilities = predicted_probabilities.div(predicted_probabilities.sum(axis=1), axis=0)\n",
    "    return predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_class(df):\n",
    "    new_df = df.copy()\n",
    "    new_df[\"highest_prob\"] = df.max(axis=1)\n",
    "    new_df[\"best_class\"] = df.idxmax(axis=1)\n",
    "    new_df[\"second_highest_prob\"] = df.apply(lambda x: x.nlargest(2).values[-1], axis=1)\n",
    "    new_df[\"second_best_class\"] = df.apply(lambda x: np.where(x == x.nlargest(2).values[-1])[0][0]+1, axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(model,X,y, verbose=True):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle=True, random_state = 0)\n",
    "\n",
    "    feature_imp = []\n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    acc_list = []\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n",
    "        if verbose: print(\"==fold==\", fold)\n",
    "        X_train = X.loc[train_index]\n",
    "        X_val = X.loc[val_index]\n",
    "\n",
    "        y_train = y.loc[train_index]\n",
    "        y_val = y.loc[val_index]\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        y_pred_list = np.append(y_pred_list, y_pred)\n",
    "        y_true_list = np.append(y_true_list, y_val)\n",
    "\n",
    "        acc_list.append(accuracy_score(y_pred, y_val))\n",
    "        if verbose: print('Acc', accuracy_score(y_pred, y_val))\n",
    "\n",
    "        try:\n",
    "            feature_imp.append(model.feature_importances_)\n",
    "        except AttributeError: # if model does not have .feature_importances_ attribute\n",
    "            pass # returns empty list\n",
    "            \n",
    "    return feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X, y):\n",
    "    for model_name, model in models.items():\n",
    "        print(\"===\",model_name,\"===\")\n",
    "        feature_imp, y_pred_list, y_true_list, acc_list, X_val, y_val = k_fold_cv(model=model,X=X,y=y, verbose=False)\n",
    "        acc_score = accuracy_score(y_pred_list, y_true_list)\n",
    "        print(\"{0:0.4f}\".format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_all(X_full, X, y, models):\n",
    "    predictions = []\n",
    "    model_names = []\n",
    "    scores = []\n",
    "    for model_name, model in models.items():\n",
    "        print(\"===\",model_name,\"===\")\n",
    "        model.fit(X[selected_features_list], y)\n",
    "        preds_prob =  model.predict_proba(X_full[selected_features_list])\n",
    "        preds_prob_df = pd.DataFrame(preds_prob, columns=range(1,8), index=transformed_selected_data.index)\n",
    "        db, ch, s = score_clusters(transformed_selected_data[selected_features_list], preds_prob_df.idxmax(axis=1), verbose=True)\n",
    "        scores.append((db,ch,s))\n",
    "        predictions.append(preds_prob_df)\n",
    "        model_names.append(model_name)\n",
    "    \n",
    "    return predictions, model_names, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_predictions(predict_number, y):\n",
    "    for i in range(predict_number):\n",
    "        print(\"=========\", i, \"==========\")\n",
    "        transformed_selected_data_sample = transformed_selected_data.sample(50000)\n",
    "        y_sample = y.loc[transformed_selected_data_sample.index]\n",
    "        \n",
    "        bgmmC = BayesianGMMClassifier(\n",
    "        n_components=7,\n",
    "        random_state = i,\n",
    "        tol =1e-3,\n",
    "        covariance_type = 'full',\n",
    "        max_iter = 300,\n",
    "        n_init=3,\n",
    "        init_params='kmeans')\n",
    "        \n",
    "        bgmmC.fit(transformed_selected_data_sample[selected_features_list], y_sample)\n",
    "        \n",
    "        pred_probs = bgmmC.predict_proba(transformed_selected_data[selected_features_list])\n",
    "        pred_probs = pd.DataFrame(pred_probs, columns=range(1,8))\n",
    "        \n",
    "        # lets score the cluster labels each iteration\n",
    "        score_clusters(transformed_selected_data[selected_features_list], pred_probs.idxmax(axis=1), verbose=True)\n",
    "        y = pred_probs.idxmax(axis=1)\n",
    "        \n",
    "    return pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "model_et = ExtraTreesClassifier(n_estimators=2000, n_jobs=-1, random_state=42)\n",
    "model_lgbm = LGBMClassifier(objective='multiclass', n_jobs=-1, n_estimators=5000, random_state=42, learning_rate=0.1, verbose=-1)\n",
    "model_qda = QuadraticDiscriminantAnalysis()\n",
    "model_lda = LinearDiscriminantAnalysis()\n",
    "model_bgmm = BayesianGMMClassifier(n_components=7, random_state=1, tol=1e-3, covariance_type='full', max_iter=400, n_init=4, init_params='kmeans')\n",
    "\n",
    "models = {\"ET\": model_et, \"LGBM\": model_lgbm, \"QDA\": model_qda, \"LDA\": model_lda, \"BGMM_C\": model_bgmm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgmm = BayesianGaussianMixture(n_components=7, covariance_type = 'full', n_init=3, random_state=2)\n",
    "predicted_class = bgmm.fit_predict(transformed_selected_data)\n",
    "data_copy[\"class\"] = predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 0 ==========\n",
      "David Bouldin score: 3.5742\n",
      "Calinski Harabasz score: 3890.478\n",
      "Silhouette score: 0.0380\n",
      "========= 1 ==========\n",
      "David Bouldin score: 3.5760\n",
      "Calinski Harabasz score: 3891.594\n",
      "Silhouette score: 0.0379\n",
      "========= 2 ==========\n",
      "David Bouldin score: 3.6002\n",
      "Calinski Harabasz score: 3903.990\n",
      "Silhouette score: 0.0383\n",
      "========= 3 ==========\n",
      "David Bouldin score: 3.5958\n",
      "Calinski Harabasz score: 3897.437\n",
      "Silhouette score: 0.0380\n",
      "========= 4 ==========\n",
      "David Bouldin score: 3.6048\n",
      "Calinski Harabasz score: 3908.253\n",
      "Silhouette score: 0.0384\n",
      "========= 5 ==========\n",
      "David Bouldin score: 3.5985\n",
      "Calinski Harabasz score: 3903.052\n",
      "Silhouette score: 0.0383\n",
      "========= 6 ==========\n",
      "David Bouldin score: 3.5940\n",
      "Calinski Harabasz score: 3902.554\n",
      "Silhouette score: 0.0382\n",
      "========= 7 ==========\n",
      "David Bouldin score: 3.6027\n",
      "Calinski Harabasz score: 3905.675\n",
      "Silhouette score: 0.0383\n",
      "========= 8 ==========\n",
      "David Bouldin score: 3.6001\n",
      "Calinski Harabasz score: 3906.472\n",
      "Silhouette score: 0.0383\n",
      "========= 9 ==========\n",
      "David Bouldin score: 3.5987\n",
      "Calinski Harabasz score: 3904.303\n",
      "Silhouette score: 0.0382\n"
     ]
    }
   ],
   "source": [
    "pred_probs = soft_voting(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_class_probs = best_class(pred_probs)\n",
    "second_highest_probs_sum = cluster_class_probs.groupby([\"best_class\", \"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n",
    "confident_predictions = cluster_class_probs.loc[cluster_class_probs[\"highest_prob\"] >= 0.8]\n",
    "confident_predictions_class = confident_predictions[\"best_class\"]\n",
    "transformed_selected_data[\"class\"] = confident_predictions_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = transformed_selected_data.loc[transformed_selected_data[\"class\"] == transformed_selected_data[\"class\"]]\n",
    "test_df = transformed_selected_data.loc[transformed_selected_data[\"class\"] != transformed_selected_data[\"class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.pop(\"class\").reset_index(drop=True)\n",
    "X = train_df.reset_index(drop=True)\n",
    "X_full = transformed_selected_data.drop(columns=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_models(models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ET ===\n",
      "David Bouldin score: 3.4441\n",
      "Calinski Harabasz score: 4088.419\n",
      "Silhouette score: 0.0437\n",
      "=== LGBM ===\n",
      "David Bouldin score: 3.5674\n",
      "Calinski Harabasz score: 3992.605\n",
      "Silhouette score: 0.0405\n",
      "=== QDA ===\n",
      "David Bouldin score: 3.5601\n",
      "Calinski Harabasz score: 4018.298\n",
      "Silhouette score: 0.0412\n",
      "=== LDA ===\n",
      "David Bouldin score: 3.0707\n",
      "Calinski Harabasz score: 4710.465\n",
      "Silhouette score: 0.0573\n",
      "=== BGMM_C ===\n",
      "David Bouldin score: 3.6167\n",
      "Calinski Harabasz score: 3923.061\n",
      "Silhouette score: 0.0381\n"
     ]
    }
   ],
   "source": [
    "predictions, model_names, scores = fit_predict_all(X_full, X, y, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_class_probs = cluster_class_probs.loc[:,[1,2,3,4,5,6,7]]\n",
    "predictions.append(cluster_class_probs)\n",
    "model_names.append(\"BGMM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Bouldin score: 3.5987\n",
      "Calinski Harabasz score: 3904.303\n",
      "Silhouette score: 0.0382\n"
     ]
    }
   ],
   "source": [
    "db, ch, s = score_clusters(transformed_selected_data[selected_features_list], cluster_class_probs.idxmax(axis=1), verbose=True)\n",
    "scores.append((db,ch,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "David Bouldin score: 3.5498\n",
      "Calinski Harabasz score: 4011.578\n",
      "Silhouette score: 0.0409\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Davies-Bouldin Index</th>\n",
       "      <th>Calinski-Harabasz Index</th>\n",
       "      <th>Silhouette Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ET</th>\n",
       "      <td>3.444140</td>\n",
       "      <td>4088.419065</td>\n",
       "      <td>0.043688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>3.567441</td>\n",
       "      <td>3992.605113</td>\n",
       "      <td>0.040515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>3.560056</td>\n",
       "      <td>4018.298105</td>\n",
       "      <td>0.041151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>3.070679</td>\n",
       "      <td>4710.465486</td>\n",
       "      <td>0.057302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGMM_C</th>\n",
       "      <td>3.616687</td>\n",
       "      <td>3923.060533</td>\n",
       "      <td>0.038052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BGMM</th>\n",
       "      <td>3.598653</td>\n",
       "      <td>3904.303144</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <td>3.549824</td>\n",
       "      <td>4011.578270</td>\n",
       "      <td>0.040939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Davies-Bouldin Index  Calinski-Harabasz Index  \\\n",
       "ET                    3.444140              4088.419065   \n",
       "LGBM                  3.567441              3992.605113   \n",
       "QDA                   3.560056              4018.298105   \n",
       "LDA                   3.070679              4710.465486   \n",
       "BGMM_C                3.616687              3923.060533   \n",
       "BGMM                  3.598653              3904.303144   \n",
       "combined              3.549824              4011.578270   \n",
       "\n",
       "          Silhouette Coefficient  \n",
       "ET                      0.043688  \n",
       "LGBM                    0.040515  \n",
       "QDA                     0.041151  \n",
       "LDA                     0.057302  \n",
       "BGMM_C                  0.038052  \n",
       "BGMM                    0.038217  \n",
       "combined                0.040939  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 0 ==========\n",
      "David Bouldin score: 3.6310\n",
      "Calinski Harabasz score: 3899.083\n",
      "Silhouette score: 0.0376\n",
      "========= 1 ==========\n",
      "David Bouldin score: 3.6893\n",
      "Calinski Harabasz score: 3805.025\n",
      "Silhouette score: 0.0353\n",
      "========= 2 ==========\n",
      "David Bouldin score: 3.7564\n",
      "Calinski Harabasz score: 3736.992\n",
      "Silhouette score: 0.0338\n",
      "========= 3 ==========\n",
      "David Bouldin score: 3.7969\n",
      "Calinski Harabasz score: 3692.862\n",
      "Silhouette score: 0.0329\n",
      "========= 4 ==========\n",
      "David Bouldin score: 3.8316\n",
      "Calinski Harabasz score: 3669.985\n",
      "Silhouette score: 0.0325\n",
      "========= 5 ==========\n",
      "David Bouldin score: 3.8564\n",
      "Calinski Harabasz score: 3645.602\n",
      "Silhouette score: 0.0321\n",
      "========= 6 ==========\n",
      "David Bouldin score: 3.8707\n",
      "Calinski Harabasz score: 3632.882\n",
      "Silhouette score: 0.0319\n",
      "========= 7 ==========\n",
      "David Bouldin score: 3.8807\n",
      "Calinski Harabasz score: 3623.406\n",
      "Silhouette score: 0.0317\n",
      "========= 8 ==========\n",
      "David Bouldin score: 3.8956\n",
      "Calinski Harabasz score: 3612.355\n",
      "Silhouette score: 0.0315\n",
      "========= 9 ==========\n",
      "David Bouldin score: 3.8977\n",
      "Calinski Harabasz score: 3604.456\n",
      "Silhouette score: 0.0313\n",
      "========= 10 ==========\n",
      "David Bouldin score: 3.8988\n",
      "Calinski Harabasz score: 3602.594\n",
      "Silhouette score: 0.0312\n",
      "========= 11 ==========\n",
      "David Bouldin score: 3.8984\n",
      "Calinski Harabasz score: 3602.459\n",
      "Silhouette score: 0.0312\n",
      "========= 12 ==========\n",
      "David Bouldin score: 3.9049\n",
      "Calinski Harabasz score: 3598.628\n",
      "Silhouette score: 0.0311\n",
      "========= 13 ==========\n",
      "David Bouldin score: 3.9025\n",
      "Calinski Harabasz score: 3599.018\n",
      "Silhouette score: 0.0311\n",
      "========= 14 ==========\n",
      "David Bouldin score: 3.9070\n",
      "Calinski Harabasz score: 3596.346\n",
      "Silhouette score: 0.0310\n",
      "========= 15 ==========\n",
      "David Bouldin score: 3.9068\n",
      "Calinski Harabasz score: 3596.911\n",
      "Silhouette score: 0.0310\n",
      "========= 16 ==========\n",
      "David Bouldin score: 3.9067\n",
      "Calinski Harabasz score: 3597.293\n",
      "Silhouette score: 0.0310\n",
      "========= 17 ==========\n",
      "David Bouldin score: 3.9091\n",
      "Calinski Harabasz score: 3595.650\n",
      "Silhouette score: 0.0310\n",
      "========= 18 ==========\n",
      "David Bouldin score: 3.9048\n",
      "Calinski Harabasz score: 3594.217\n",
      "Silhouette score: 0.0310\n",
      "========= 19 ==========\n",
      "David Bouldin score: 3.9070\n",
      "Calinski Harabasz score: 3593.190\n",
      "Silhouette score: 0.0310\n",
      "========= 20 ==========\n",
      "David Bouldin score: 3.9045\n",
      "Calinski Harabasz score: 3593.894\n",
      "Silhouette score: 0.0310\n",
      "========= 21 ==========\n",
      "David Bouldin score: 3.9083\n",
      "Calinski Harabasz score: 3592.815\n",
      "Silhouette score: 0.0309\n",
      "========= 22 ==========\n",
      "David Bouldin score: 3.9037\n",
      "Calinski Harabasz score: 3598.345\n",
      "Silhouette score: 0.0311\n",
      "========= 23 ==========\n",
      "David Bouldin score: 3.9051\n",
      "Calinski Harabasz score: 3598.698\n",
      "Silhouette score: 0.0311\n",
      "========= 24 ==========\n",
      "David Bouldin score: 3.9035\n",
      "Calinski Harabasz score: 3597.656\n",
      "Silhouette score: 0.0311\n",
      "========= 25 ==========\n",
      "David Bouldin score: 3.9070\n",
      "Calinski Harabasz score: 3597.245\n",
      "Silhouette score: 0.0311\n",
      "========= 26 ==========\n",
      "David Bouldin score: 3.9107\n",
      "Calinski Harabasz score: 3597.611\n",
      "Silhouette score: 0.0311\n",
      "========= 27 ==========\n",
      "David Bouldin score: 3.9037\n",
      "Calinski Harabasz score: 3598.062\n",
      "Silhouette score: 0.0311\n",
      "========= 28 ==========\n",
      "David Bouldin score: 3.9054\n",
      "Calinski Harabasz score: 3597.999\n",
      "Silhouette score: 0.0311\n",
      "========= 29 ==========\n",
      "David Bouldin score: 3.8986\n",
      "Calinski Harabasz score: 3598.195\n",
      "Silhouette score: 0.0311\n",
      "========= 30 ==========\n",
      "David Bouldin score: 3.8962\n",
      "Calinski Harabasz score: 3597.190\n",
      "Silhouette score: 0.0311\n",
      "========= 31 ==========\n",
      "David Bouldin score: 3.8989\n",
      "Calinski Harabasz score: 3594.569\n",
      "Silhouette score: 0.0310\n",
      "========= 32 ==========\n",
      "David Bouldin score: 3.8998\n",
      "Calinski Harabasz score: 3598.395\n",
      "Silhouette score: 0.0311\n",
      "========= 33 ==========\n",
      "David Bouldin score: 3.8990\n",
      "Calinski Harabasz score: 3596.537\n",
      "Silhouette score: 0.0311\n",
      "========= 34 ==========\n",
      "David Bouldin score: 3.8995\n",
      "Calinski Harabasz score: 3593.209\n",
      "Silhouette score: 0.0310\n",
      "========= 35 ==========\n",
      "David Bouldin score: 3.9024\n",
      "Calinski Harabasz score: 3594.340\n",
      "Silhouette score: 0.0310\n",
      "========= 36 ==========\n",
      "David Bouldin score: 3.9003\n",
      "Calinski Harabasz score: 3597.036\n",
      "Silhouette score: 0.0311\n",
      "========= 37 ==========\n",
      "David Bouldin score: 3.9009\n",
      "Calinski Harabasz score: 3597.899\n",
      "Silhouette score: 0.0310\n",
      "========= 38 ==========\n",
      "David Bouldin score: 3.9067\n",
      "Calinski Harabasz score: 3598.836\n",
      "Silhouette score: 0.0311\n",
      "========= 39 ==========\n",
      "David Bouldin score: 3.9063\n",
      "Calinski Harabasz score: 3600.909\n",
      "Silhouette score: 0.0311\n",
      "========= 40 ==========\n",
      "David Bouldin score: 3.9053\n",
      "Calinski Harabasz score: 3599.015\n",
      "Silhouette score: 0.0310\n",
      "========= 41 ==========\n",
      "David Bouldin score: 3.9044\n",
      "Calinski Harabasz score: 3594.727\n",
      "Silhouette score: 0.0310\n",
      "========= 42 ==========\n",
      "David Bouldin score: 3.9032\n",
      "Calinski Harabasz score: 3595.329\n",
      "Silhouette score: 0.0310\n",
      "========= 43 ==========\n",
      "David Bouldin score: 3.9161\n",
      "Calinski Harabasz score: 3589.122\n",
      "Silhouette score: 0.0309\n",
      "========= 44 ==========\n",
      "David Bouldin score: 3.9123\n",
      "Calinski Harabasz score: 3592.332\n",
      "Silhouette score: 0.0310\n",
      "========= 45 ==========\n",
      "David Bouldin score: 3.9078\n",
      "Calinski Harabasz score: 3594.291\n",
      "Silhouette score: 0.0310\n",
      "========= 46 ==========\n",
      "David Bouldin score: 3.9063\n",
      "Calinski Harabasz score: 3597.932\n",
      "Silhouette score: 0.0310\n",
      "========= 47 ==========\n",
      "David Bouldin score: 3.9003\n",
      "Calinski Harabasz score: 3597.825\n",
      "Silhouette score: 0.0311\n",
      "========= 48 ==========\n",
      "David Bouldin score: 3.8983\n",
      "Calinski Harabasz score: 3597.227\n",
      "Silhouette score: 0.0311\n",
      "========= 49 ==========\n",
      "David Bouldin score: 3.8984\n",
      "Calinski Harabasz score: 3598.737\n",
      "Silhouette score: 0.0311\n",
      "========= 50 ==========\n",
      "David Bouldin score: 3.8986\n",
      "Calinski Harabasz score: 3599.134\n",
      "Silhouette score: 0.0311\n",
      "========= 51 ==========\n",
      "David Bouldin score: 3.9065\n",
      "Calinski Harabasz score: 3595.388\n",
      "Silhouette score: 0.0309\n",
      "========= 52 ==========\n",
      "David Bouldin score: 3.9089\n",
      "Calinski Harabasz score: 3592.129\n",
      "Silhouette score: 0.0310\n",
      "========= 53 ==========\n",
      "David Bouldin score: 3.9027\n",
      "Calinski Harabasz score: 3595.539\n",
      "Silhouette score: 0.0310\n",
      "========= 54 ==========\n",
      "David Bouldin score: 3.9042\n",
      "Calinski Harabasz score: 3598.292\n",
      "Silhouette score: 0.0310\n",
      "========= 55 ==========\n",
      "David Bouldin score: 3.9027\n",
      "Calinski Harabasz score: 3598.569\n",
      "Silhouette score: 0.0311\n",
      "========= 56 ==========\n",
      "David Bouldin score: 3.9118\n",
      "Calinski Harabasz score: 3593.065\n",
      "Silhouette score: 0.0309\n",
      "========= 57 ==========\n",
      "David Bouldin score: 3.9082\n",
      "Calinski Harabasz score: 3594.863\n",
      "Silhouette score: 0.0309\n",
      "========= 58 ==========\n",
      "David Bouldin score: 3.9016\n",
      "Calinski Harabasz score: 3595.386\n",
      "Silhouette score: 0.0310\n",
      "========= 59 ==========\n",
      "David Bouldin score: 3.9012\n",
      "Calinski Harabasz score: 3598.397\n",
      "Silhouette score: 0.0310\n",
      "========= 60 ==========\n",
      "David Bouldin score: 3.9075\n",
      "Calinski Harabasz score: 3593.472\n",
      "Silhouette score: 0.0310\n",
      "========= 61 ==========\n",
      "David Bouldin score: 3.9045\n",
      "Calinski Harabasz score: 3593.981\n",
      "Silhouette score: 0.0309\n",
      "========= 62 ==========\n",
      "David Bouldin score: 3.9119\n",
      "Calinski Harabasz score: 3593.915\n",
      "Silhouette score: 0.0309\n",
      "========= 63 ==========\n",
      "David Bouldin score: 3.9122\n",
      "Calinski Harabasz score: 3593.085\n",
      "Silhouette score: 0.0310\n",
      "========= 64 ==========\n",
      "David Bouldin score: 3.9000\n",
      "Calinski Harabasz score: 3596.322\n",
      "Silhouette score: 0.0311\n",
      "========= 65 ==========\n",
      "David Bouldin score: 3.9172\n",
      "Calinski Harabasz score: 3592.117\n",
      "Silhouette score: 0.0310\n",
      "========= 66 ==========\n",
      "David Bouldin score: 3.9163\n",
      "Calinski Harabasz score: 3590.568\n",
      "Silhouette score: 0.0309\n",
      "========= 67 ==========\n",
      "David Bouldin score: 3.9110\n",
      "Calinski Harabasz score: 3591.616\n",
      "Silhouette score: 0.0310\n",
      "========= 68 ==========\n",
      "David Bouldin score: 3.9088\n",
      "Calinski Harabasz score: 3592.945\n",
      "Silhouette score: 0.0309\n",
      "========= 69 ==========\n",
      "David Bouldin score: 3.9044\n",
      "Calinski Harabasz score: 3595.585\n",
      "Silhouette score: 0.0311\n",
      "========= 70 ==========\n",
      "David Bouldin score: 3.9148\n",
      "Calinski Harabasz score: 3592.004\n",
      "Silhouette score: 0.0309\n",
      "========= 71 ==========\n",
      "David Bouldin score: 3.9141\n",
      "Calinski Harabasz score: 3592.622\n",
      "Silhouette score: 0.0309\n",
      "========= 72 ==========\n",
      "David Bouldin score: 3.9072\n",
      "Calinski Harabasz score: 3597.493\n",
      "Silhouette score: 0.0311\n",
      "========= 73 ==========\n",
      "David Bouldin score: 3.9067\n",
      "Calinski Harabasz score: 3598.224\n",
      "Silhouette score: 0.0310\n",
      "========= 74 ==========\n",
      "David Bouldin score: 3.9059\n",
      "Calinski Harabasz score: 3598.252\n",
      "Silhouette score: 0.0311\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/tabular-playground-series-jul-2022/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m best_class(predicted_probabilities)\n\u001b[0;32m     18\u001b[0m second_highest_probs_sum \u001b[38;5;241m=\u001b[39m predictions_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_class\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_best_class\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_highest_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m---> 19\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/tabular-playground-series-jul-2022/sample_submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m submission[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_class\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     21\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Datasets/submissions_semisupervised/submission_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (w_1, w_2, w_3, w_4, w_5), index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\bilal\\miniconda3\\envs\\ml_env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/tabular-playground-series-jul-2022/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "for w_1 in [0.5, 1.5]:\n",
    "        for w_2 in [0.5, 1.5]:\n",
    "            for w_3 in [0.5, 1.5]:\n",
    "                for w_4 in [0.5, 1.5]:\n",
    "                    for w_5 in [0.5, 1.5]:\n",
    "                        predictions_df = w_1 * predictions[0] + w_2 * predictions[1] + w_3 * predictions[2] + w_4 * predictions[4] + w_5 * predictions[5]\n",
    "                        predictions_df = predictions_df.div(predictions_df.sum(axis = 1), axis = 0)\n",
    "                        predictions_df = best_class(predictions_df)\n",
    "\n",
    "                        db, ch, s = score_clusters(transformed_selected_data[selected_features_list], predictions_df[\"best_class\"], verbose = True)\n",
    "                        scores.append((db,ch,s))\n",
    "                        model_names.append(\"combined\")\n",
    "                        display(pd.DataFrame(scores, index=model_names, columns=[\"Davies-Bouldin Index\",\"Calinski-Harabasz Index\",\"Silhouette Coefficient\"]))\n",
    "                        second_highest_probs_sum = predictions_df.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n",
    "\n",
    "                        predicted_probabilities = update_predictions(predict_number = 25, y = predictions_df[\"best_class\"])\n",
    "                        predictions_df = best_class(predicted_probabilities)\n",
    "                        second_highest_probs_sum = predictions_df.groupby([\"best_class\",\"second_best_class\"])[\"second_highest_prob\"].sum().reset_index()\n",
    "                        submission[\"Predicted\"] = predictions_df[\"best_class\"]\n",
    "                        submission.to_csv('../Datasets/submissions_semisupervised/submission_%s_%s_%s_%s_%s.csv' % (w_1, w_2, w_3, w_4, w_5), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"Predicted\"] = predictions_df[\"best_class\"]\n",
    "submission.to_csv('../Datasets/submissions_semisupervised/submission_%s_%s_%s_%s_%s.csv' % (w_1, w_2, w_3, w_4, w_5), index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
